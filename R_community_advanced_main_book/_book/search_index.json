[["01-R_community_advanced_main_book.html", "R community advanced analysis Chapter 1 Introduction Table of contents", " R community advanced analysis Matthew R. Gemmell 2024-07-08 Chapter 1 Introduction ADD NEW COURSE LOGO ADD NEW COURSE INTRO Table of contents ADD TABLE OF CONTENTS This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Dataset_and_workflow.html", "Chapter 2 Dataset &amp; workflow 2.1 Dataset 2.2 Workflow", " Chapter 2 Dataset &amp; workflow 2.1 Dataset In this tutorial we will be using a 16S metabarcoding dataset derived from surface water from the Durance River in the south-east of France. Two major comparisons were carried out in combination with each other. Link to paper 2.1.1 Sites Three different sites were chosen on the Durance River. These three sites were representative of an anthropisation (transformation of land by humans) gradient along a river stream. These sites were: Upper Durance sampling site (UD): Alpine part of the river with little/no anthropisation. Middle Durance sampling site (MD): Upper part of agricultural land dominated by apple and pear production. Lower Durance sampling site (LD): Lower part of agricultural land with intensive production of fruits, cereals, and vegetables. 2.1.2 Culture media Surface water was sampled and different culture media were used to produce bacterial lawns for each site. The media used were: Environmental sample (ENV): No media used, frozen at -20°C. TSA 10% incubated at 28°C for 2 days. KBC incubated at 28°C for 2 days. CVP incubated at 28°C for 3 days. 2.1.3 Summary &amp; questions Each sample and media combination was produced in replicates of three giving a total of 36 samples (3 X 4 X 3 = 36). The three replicates were cultured on three different plates with the same media. An ASV table, taxonomy table, and phylogenetic tree were produced with QIIME2 and DADA2. With this data we can ask and investigate the following questions: How do the bacterial communities change across the anthropisation gradient? Is there a difference in the replicates of one site and media combination? I.e. do any of the media produce inconsistent profiles? Is there more difference between the sites or the media used? Do the media samples differ from the ENV samples? If so, how? 2.2 Workflow Import: Import QIIME2 artifacts into a phyloseq object with qiime2R. Summarisations: Check our phyloseq object with summarisations. Minimum depth: Determine the minimum depth we should use and remove samples with lower depth. Taxanomic relative abundance: Create taxonomic relative abundance tables. Taxa plots: Produce heat maps and bar plots of taxa relative abundances. Family and genus: Using the last step to produce family and genus based taxa plots. Rarefaction: Carry out sample depth normalisation with rarefactions. This will be used for alpha and beta diversity analysis. Alpha diversity: Carry out alpha diversity analysis through plots and statistics. Beta diversity: Carry out beta diversity analysis through plots and statistics. Differenital abundance anlaysis: Detect biomarkers compared to a reference group with ANCOM. "],["03-R_packages.html", "Chapter 3 R Packages 3.1 R packages/libraries 3.2 The grammar of graphics 3.3 phyloseq", " Chapter 3 R Packages During this workshop we will use various R packages with their own intricacies. Before going into analysis we'll introduce you to some of these important concepts. 3.1 R packages/libraries R packages/libraries contain additional functions, data and code for analysing, manipulating and plotting different types of data. Many common packages will be installed as default when you install R. Other more specialised packages, such as the ggplot2 package, must be installed by the user. Packages found on The Comprehensive R Archive Network (CRAN), R’s central software repository, can be installed using the following command. install.packages(&quot;package_name&quot;) Every time you reload R you will need to load the packages you require if they are not installed in R by default. To do this type: library(&quot;package_name&quot;) I generally have a list of library() functions at the top of my R scripts (.R files) for all the packages I use in the script. Throughout this course you will get a lot of practice installing and loading various packages. R package or R Library? R packages are a collection of R functions, data, and compiled code. You can install these into a directory on your computer. An R library is a directory containing a R package. Because of this, the terms R package and R library may be used synonymously. We will use the term package in this workshop. As we will be using a lot of packages we shall use double colons (::) to specify which package each function belongs to, unless the function is from base R. For example if we use the function summarize_phyloseq() from the package microbiome we would type the function like below: Note: Do not run the below command. microbiome::summarize_phyloseq() This convention has 2 benefits: We can easily tell which R package each function comes from. This is useful for your future coding where you may copy some, but not all, commands from one script to another. You will therefore know which packages you will need to load. If you need some more documentation about a function you will know what package to look up. Writing your methods will be a lot easier. Different packages may have functions with the same name. Specifying the package will ensure you are using the correct function. 3.2 The grammar of graphics During this course we will be using the grammar of graphics coding approach. This approach is implemented by the R package ggplot2 to create visualisations such as bar charts, box plots, ordination plots etc. In turn ggplot2 is used by a host of other packages, some of which we will be using. Although ggplot2 is R code, its structure is very different and it takes effort to learn. Thankfully, ggplot2 is very powerful and flexible, and it produces very professional and clean plots. We will use the iris dataset (inbuilt into R) to show an example of ggplot2 code and its visualisation output. You don't need to run the below code. Note: If you would like to see the contents of the iris dataset you can run the command View(iris) in your R instance later. #Load library library(ggplot2) #Create new ggplot2 object using iris dataset ggplot2::ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + #Make the object a scatter plot ggplot2::geom_point() + #Add plot tile ggplot2::ggtitle(&quot;Iris Sepal length vs width&quot;) + #Set x and y axis label names ggplot2::labs(x = &quot;Sepal length&quot;, y = &quot;Sepal width&quot;) We will not learn ggplot2 specifically during this course. However, the structure of creating an object will be used. In the above case the initial object was built with ggplot. Subsequently additions and edits were carried out with + and various other functions. An important concept of the grammar of graphics is aesthetics. Aesthetics are the parts of a graphic/plot. In the above command we set the aesthetics with the function aes() within the ggplot() function. The X aesthetic (i.e. what values are assigned to the x axis) was set as the Sepal length values from the column Sepal.Length of the dataframe iris. In turn the Y axis values are set to the Sepal width and the colouring of the points are set to the Species. That was a quick introduction to the grammar of graphics. We will be using this to create visualisations with a phyloseq object using various R packages specifically designed for community abundance data within phyloseq objects. For more resources on ggplot2 please see the appendix of this book. 3.3 phyloseq In this book we will be working with phyloseq objects to preprocess our dataset, create visualisations, and carry out statistical analyses. This is a very popular object type for community abundance datasets as it contains the abundance table, metadata, and taxonomy table in one object, optionally containing the phylogenetic tree and reference sequences if wanted/required. For more info on phyloseq and associated packages please see the appendix. "],["04-Setup.html", "Chapter 4 Set-up 4.1 Logon instructions 4.2 Mamba", " Chapter 4 Set-up Prior to any analysis we need to setup our environment in the webVNC. 4.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. You will most likely need to use your browser's tool bar to accomplish this. Ensure you can see the grey borders. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Mint Linux The following link is a guide to install Mint Linux: https://linuxmint-installation-guide.readthedocs.io/en/latest/ 4.2 Mamba This workshop requires a lot of packages. These all can be difficult to install with R. Instead we have used Mamba forge to install R, its packages, and Jupyter-notebook (more info below). To learn more about Mamba-forge and how to create your own environment please see the appendix. To set-up your environment for this workshop please run the following code (you must include the full stop and space at the front of the command). . usercommunity You will have successfully activated the environment if you now see (r_community) at the start of your command prompt. This indicates you are now in the mamba environment called r_community created by the instructor. If you are interested in the use script you can look at its contents. less /usr/local/bin/usercommunity Tip: press q to quit less. For more about mamba and how to create your own r_community environment please see the appendix "],["05-Jupyter.html", "Chapter 5 Jupyter 5.1 Open Jupyter-notebook 5.2 Create R notebook 5.3 Cells and code 5.4 Create new cells 5.5 Running code 5.6 Saving the file 5.7 Title cells with markdown 5.8 Close the notebook 5.9 Video tutorial", " Chapter 5 Jupyter Jupyter-notebook is a nice browser based method to write, edit, and run code. It was initally created for Python coding, but has since branched out to many other languages, such as R. We are using it in this workshop for a variety of its properties: It is popular and well maintained. It is lightweight. Other heavier weight programs, such as RStudio, would struggle in our HPC due to the graphical and CPU load. It is interactive and displays code output. It allows for easier annotation, editing, and debugging than the command line. It provides a graphical interface for changing directories and choosing files. Before carrying out any analysis we will go through a quick tutorial of jupyter-notebook. Note: There is a video tutorial of this chapter at the bottom of this page if you prefer to watch it. 5.1 Open Jupyter-notebook The first step is to open jupyter-notebook. Run the below command in your (r_community) environment. jupyter-notebook This will open jupyter-notebook in firefox. We won't need to access the linux terminal anymore. Leave the terminal running jupyter-notebook and full screen your firefox so you should see something like below. Can't see the whole webVNC window? You may need to zoom out with your browser so you can see the full webVNC window. Chrome: Click on the three dots in vertical line ( ) on the top left for a dropdown menu which includes zoom options. Edge: Click on the three horizontal lines ( ) on the top left for a dropdown menu which includes zoom options. Firefox: Click on the three dots in horizontal line ( ) on the top left for a dropdown menu which includes zoom options. 5.2 Create R notebook The next step is to create an R notebook. Click on the \"New\" button towards the top right, right of the \"Upload\" button. From the dropdown click \"R\" below \"Python 3 (ipykernel)\". This will open up a new R notebook like below. 5.3 Cells and code Jupyter-notebook uses cells (the grey boxes) to separate code. This is very useful to compartmentalise our code. There will already be one cell. Within the cell, type in the below commands. 1+1 2-3 When pressing enter in cells it will create a new line. To run all commands in a cell press CTRL + enter. Run your current cell and you should see something like below. 5.4 Create new cells You can create new cells by 2 different means. Press the + button on the tool bar (between the floppy disk and scissors ). This will add a cell below your currently selected cell. Click on the Insert button and use the dropdown to add a cell above or below your currently selected cell. Tip: Hover over the toolbar icons to display a text based description of its function. With that knowledge add a second cell below the first cell. Add the following code to your second cell but do not run it. num_1 &lt;- 3 num_2 &lt;- 10 Tip: Notice there are green lines around your selected cell. Insert a third cell and add the following code to it. Do not run the code. num_1 * num_2 5.5 Running code Try to run the code in the third cell. There should be an error as we have not created the objects num_1 &amp; num_2. We have only written the code for these objects but not run them. We can run all the code in a notebook starting from the first cell to the last cell. To run all cells from the start: Click on the \"Cell\" button. Click \"Run All\" from the drop-down options. You should then see something like the below in your notebook. There is no output printed for cell 2 because we are assigning variables. However, the correct output for Cell 3 is below it. This is because the variables were assigned in cell 2 before cell 3 was run. 5.6 Saving the file As with RStudio and other good coding interfaces we can save our notebook. First we should rename the file. Rename the notebook to \"jupyter_tut.ipynb\": Click on the name of the notebook, currently called \"Untitled\". This is at the very top of the notebook, right of the Jupyter logo. A pop-up called \"Rename Notebook\" will appear. Change the Name to \"jupyter_tut.ipynb\". Click \"Rename\". Now we can save the file. Two methods to save are: Click the floppy disk on the toolbar. Click on the \"File\" button. Click \"Save and Checkpoint\" from the dropdown options. 5.7 Title cells with markdown We will be using multiple notebooks in this workshop. We will also have multiple sections per notebook. It will be useful to create header cells with markdown to create visual separation of the different sections. To add a header cell to the top of our notebook: Create a new cell at the top of the notebook. Click on the \"Code\" drop down and select \"Markdown\". The \"Heading\" option no longer works. Add the following to the \"Markdown\" cell to create a first level header. Ensure you have a space between the # and header text (\"Tutorial\"). # Tutorial Great, we can now add nice headers in our notebooks. Save the notebook once more before carrying on to the next section. Markdown You won't need to know more about Markdown but if you are interested please see the Markdown guide. 5.8 Close the notebook To close the notebook: Click on \"File\". From the dropdown options click \"Close and Halt\". When you are back in the file explorer page you may not yet see the new file you saved. If so, you will need to refresh the page with the Refresh button towards the top right. With that quick tutorial of jupyter-notebook we can start our community analysis in the next chapter. For more info on jupter-notebook please see the appendix. 5.9 Video tutorial "],["06-Iterative_rarefaction.html", "Chapter 6 Iterative rarefaction intro 6.1 Should you rarefy? 6.2 Using iterations 6.3 Section contents", " Chapter 6 Iterative rarefaction intro Rarefaction is the process of randomly subsetting samples so the total count values are identical across all samples. Rarefaction is intended to correct for bias caused by varying sampling depths across the samples to be analysed. 6.1 Should you rarefy? Rarefaction can be a hotly debated topic with two main points of view. Some researchers believe it is not appropriate. This is backed up by the 2014 paper \"Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible\" Various R package developers do not recommend it such as the developers of phyloseq &amp; microbiome. Some researchers believe it is appropriate. This is backed up by the 2022 paper \"To rarefy or not to rarefy: robustness and efficiency trade-offs of rarefying microbiome data\" The QIIME2 developers include rarefaction in their tutorials/SOPs for alpha and beta diversity analysis We use rarefaction in our analyses but it is ultimately up to you whether you utilise it or not. 6.2 Using iterations In our initial R community analysis workshop we only rarefy once for each sample. In this section we will rarefy multiple times to calculate average values for alpha and beta diversity metrics. This is iterative rarefaction analysis. This iterative approach will, in theory, smooth out any extreme results one round of rarefaction may cause. Extreme results are possibly due the random nature of rarefaction. These extreme results can include: Leaving important features (ASVs, taxonomic groups, etc.) with no counts Causing a few features to have much higher relative abundances Varying alpha and beta diversity values with different sets of rarefaction 6.3 Section contents In this section we will learn how to: Use random seeds for sampling Carry out iterative rarefaction with sets of random seeds Use iterative rarefaction to carry out alpha diversity analysis Use iterative rarefaction to carry out beta diversity analysis "],["07-Rarefaction_and_random_seeds.html", "Chapter 7 Random seeds 7.1 Random seed notebook 7.2 Random sampling 7.3 Sampling with replacement 7.4 Setting a random seed 7.5 Reset seed 7.6 Random seed practice", " Chapter 7 Random seeds What are random seeds? Random seeds are numbers that computational tasks use to determine how they will carry out a random task. In this chapter we will demonstrate the use of random seeds. This is to help understand what they are and why they are used. We won't do anything of value with the results in this chapter, instead this knowledge will be useful for understanding iterative rarefaction. 7.1 Random seed notebook Create a new R jupyter-notebook called \"Random_seeds.ipynb\". We will use this for this chapter. 7.2 Random sampling To demonstrate to use of random seed we will use the R function sample(). This function randomly samples a set of numbers. Create the below code in a code cell. #Create a vector containing the numbers 0 to 10 num_vec &lt;- 0:10 #Randomly sample 5 of these numbers sample(x = num_vec, size = 5) If you run the code you will get five random single digit numbers. Run this multiple times and you will hopefully see the sampled numbers are different every time. 7.3 Sampling with replacement You may also notice that within each sample there are no repeating numbers. You can change this by adding the options replace = TRUE. Try this out in a new cell. #Randomly sample 5 of these numbers with replacement sample(x = num_vec, size = 5, replace = TRUE) Run this a few times and you will hopefully notice that the five numbers are not always unique. When sampling with replacement you put back any results back into the sampling pool. When sampling without replacement you don't put back any results into the sampling pool. The famous example is sampling green and yellow balls from a bag. If you had a bag with 1000 balls and you wanted a rough idea of the ratio of yellow and green balls you could count the number of these balls within a sample of only 50. Without replacement you would take out a ball, record its colour and throw it in a separate container. With replacement you would take out a ball, record its colour and put it back into the initial bag, meaning it could possibly be recounted. One advantage of sampling with replacement is that your sampling size can be larger than your actual population size. For example, you could create a random sampling of 50 with a bag containing 10 balls with replacement. This would not work without replacement. The below script will cause R to produce an error saying it can be done with replacement. #Randomly sample 5 of these numbers with replacement sample(x = num_vec, size = 5, replace = TRUE) Importantly for us rarefaction uses sampling without replacement. 7.4 Setting a random seed We'll sample, without replacement, the numbers one more time in a new cell. However, this time we will set the random seed with the function seet.seed(). #Set random seed set.seed(1234) #Randomly sample 12 of these numbers without replacement sample(x = num_vec, size = 12, replace = FALSE) #Reset random seed set.seed(NULL) Before we explain the code further, try running the cell multiple times. If it is identical to the above code you will get the numbers \"9, 5, 4, 3, &amp; 6\". How come you are getting these results if it is random? True randomness is pretty much impossible, especially in computing. Therefore, many programs use seeds to determine how random tasks will be carried out. Various programs that use random seeds include: Sampling tools such as sample() and rarefaction Creating bootstrapped phylogenies Creating procedural content such as building Minecraft worlds If you run a tool that uses random sampling you will always get the same results if: You use the same random seed You use the same data You use the same parameters including the replacement method (with or without) In fact, run the below code in a new code cell and you may notice a similarity with your previous output. #Set random seed set.seed(1234) #Create a vector containing the numbers 0 to 10 larger_num_vec &lt;- 10:19 #Randomly sample 5 of these numbers sample(x = num_vec, size = 5) #Reset random seed set.seed(NULL) That's right, sample() will always take the 10th (9/19), 6th (5/15), 5th (4/14), 4th (3/13), and 7th (6/16) values if it is given the random seed of 1234, provided with an 11 length vector, and asked to sample 5 values. Setting our randomness is incredible beneficial for reproducibility in research. When you carry out analysis you may need to redo some work. This could be due to reviewer comments or you want to incorporate some new methods. As long as you saved the random seeds you used you can get the same results where you need to. It also means others can replicate your results. 7.5 Reset seed We set a random seed at the start of the cell for reproducibility and control, but why do we then run the line set.seed(NULL)? The normal operation of R means that, in effect, its random seed changes every time it is used. This means R normally randomly determines randomness. This is how it should be until we want to set the randomness. It is therefore good practice to set the seed to NULL after you have utilised your set seeds. This will revert the seed to its normal random operations. One last point to note is R versions. Version 3.6 changed R's sampling methods, therefore if you use Version 3.5 or below you will get different results than we have got. Hopefully the R developers will not change this in a later version again. 7.6 Random seed practice Brilliant! To reinforce the above knowledge try out the following challenges. First create the following vector: second_millenium &lt;- 1001:2000 Note: Remember it is best practice to set.seed(NULL) at the end of a code cell. 7.6.1 Random seed: Question 1 Sample the object second_millenium with the following parameters: Extract 10 values Without replacement Use the random seed 489 What is the fourth number in the produced vector? 1120 1369 1744 7.6.2 Random seed: Question 2 Sample the object second_millenium with the following parameters: Extract 24 values Without replacement Use the answer to the first question as the random seed What is the 16th number in the produced vector? 1120 1369 1744 7.6.3 Random seed: Question 3 Sample the object second_millenium with the following parameters: Extract a number of values equal to the answer of the second question With replacement Use the answer to the first question as the random seed What is the 999th number in the produced vector? 1120 1369 1744 Once you are happy you can save then close and halt your \"Random_seeds.ipynb\" notebook. Hopefully this has given you a good understanding of the principle of random seeds. With this you can continue onto iterative rarefaction. "],["08-Iterating_rarefaction.html", "Chapter 8 Iterating rarefaction 8.1 Iterating rarefaction dataset 8.2 Iterating rarefaction setup 8.3 Rarefaction iterations 8.4 RNG vector creation 8.5 Phyla relative abundance 8.6 One Round (1R) of rarefaction 8.7 Multiple Rarefaction (MR) iterations 8.8 Iterating rarefaction task 8.9 Iterating rarefaction recap", " Chapter 8 Iterating rarefaction In this chapter we will create code to carry out iterative rarefaction. For this we create a vector of random seeds, each used for a different iteration of rarefaction. We will loop through these random seeds, using each random seed to carry out one iteration of rarefaction. In the next chapters we will utilise this code to produce alpha and beta diversity values that we will analyse. 8.1 Iterating rarefaction dataset We will utilise the same dataset used in the R community analysis workshop. Below are brief bullet points about the data: It is a 16S dataset of ASV counts with taxonomy and phylogeny produced by QIIME2 The samples come from surface water from the Durance River in the south-east of France There are three sampling sites on an anthropisation gradient (low to high agriculture) Upper Durance (UD) Middle Durance (MD) Lower Durance (LD) Four different media approaches were used to produce bacterial lawns that were sequenced Environmental sample (ENV): No media used, frozen at -20°C. TSA 10% incubated at 28°C for 2 days. KBC incubated at 28°C for 2 days. CVP incubated at 28°C for 3 days. There are three replicates for each sampling site and media combination (36 samples total) 8.2 Iterating rarefaction setup First, create a new R jupyter-notebook called \"Iterating_rarefaction.ipynb\". At the top of this notebook create a code cell to load in the various packages and data we need. The code is below: #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) #Load processed but unrarefied data from R community analysis workshop load(&quot;phyloseq.RData&quot;) 8.3 Rarefaction iterations We need to choose the number of iterations we are going to carry out. For our practice we will use 10 iterations for speed. In your real analysis I would recommend using 1000 iterations. Let's create a variable for our number of iterations. #Number of rarefaction iterations to be carried out #Using 10 here for speed, real analysis should use 1000 rarefaction_iters &lt;- 10 8.4 RNG vector creation We can now carry out Random Number Generation (RNG) to create a number of random seeds equal to the number of iterations planned. #Create rngseed vector #Set seed for reproducibility #This number was chosen randomly set.seed(2605) #Sample 10 (number of iters) values from the number range 1-100,000 rngseed_vec &lt;- sample(x=1:100000, size = rarefaction_iters, replace = FALSE) #Print out vector rngseed_vec #Save our rngseed vector save(rngseed_vec, file=&quot;rngseeds.RData&quot;) #Reset seed set.seed(NULL) There are a lot of steps above. These are: Setting the random seed: We carry this out so we will always get the same rngseed vector that will be used for the rarefaction iterations. This is important so you will always get the same results if you need to rework some analysis, stats, or plots. Also useful here so you get the same results as the instructor and other attendees. Creating the rngseed vector: We use our old friend sample() to create a random number for each iteration we will carry out. We arbitrarily sample from the numbers 1-100,000, you could change this to a larger range in your future research. We use our previous object rarefaction_iters as size= to produce a random number for each of our iterations. We carry this out without replacement so none of our rarefaction iterations are identical. Save the rngseed vector: We save the vector as a file. We will load this in our alpha and beta diversity notebooks to be used for iterative rarefaction. This is also useful so you have a backup file of the rngseed vectors. Reset seed: Always good to reset the seed at the end of a cell. 8.5 Phyla relative abundance Prior to iterative rarefaction we will look at the phyla composition of the environmental samples. 8.5.1 Subset and phyla aggregation For demonstrative purposes we will reduce the amount of samples and features in our data for this chapter. We will carry this out by: Subsetting the data so it only contains the 9 environmental samples. Aggregate the taxa to phyla whilst aggregating rare taxa to one \"other group\" #Reduce data for demonstrative purposes #Subset phyloseq object to only retain the ENV samples #I.e. remove the media samples physeq_env &lt;- phyloseq::subset_samples(pseq, media == &quot;ENV&quot;) #Aggregate to phyla level whilst aggregating rare phyla pseq_env_phyla &lt;- microbiome::aggregate_rare(pseq_env, level = &quot;Phylum&quot;, detection = 0.1, prevalence = 0.5, verbose = FALSE) #View count table otu_table(pseq_env_phyla) #Sum count of samples microbiome::readcount(pseq_env_phyla) #Remove unwanted objects rm(pseq, pseq_env) 8.5.2 Phyla relative abundance bar chart Let's have a quick look at the non rarefied phyla relative abundance through a bar chart. Note: This is how you would normally look at this type of bar chart. #Quick phyla bar chart of relative abundance #Relative abundance transformation pseq_env_phyla_relabund &lt;- microbiome::transform(pseq_env_phyla, &quot;compositional&quot;) #Create, save, and display bar chart phylum_bar &lt;- microbiome::plot_composition(pseq_env_phyla_relabund) ggsave(filename = &quot;./env_phyla_relabund.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 100, width = 100) IRdisplay::display_png(file = &quot;./env_phyla_relabund.png&quot;) 8.6 One Round (1R) of rarefaction We will first carry out one round of rarefaction . This is so we can get a reminder of how to carry it out and to compare the results of no rarefaction and only one round. 8.6.1 1R: Rarefaction Carry out one round of rarefaction and view the rarefied counts. We are using the environmental samples subsetted and phyla aggregated data. Additionally, we are using the first of our random seeds in rng_seed_vec and the minimum read count as our rarefaction size. #One round of rarefaction pseq_env_phyla_rarefy_1 &lt;- phyloseq::rarefy_even_depth( pseq_env_phyla, #Minimum read count as rarefaction size sample.size = min(microbiome::readcount(pseq_env_phyla)), #First random seed as the rng seed rngseed = rngseed_vec[1]) #View count table otu_table(pseq_env_phyla_rarefy_1) #Sum count of samples microbiome::readcount(pseq_env_phyla_rarefy_1) You should see that all the samples now have a total count of 11046. 8.6.2 1R: Relative abundance bar chart Now to create a relative abundance bar chart with our rarefied data to compare to our non-rarefied data. #Quick phyla bar chart of relative abundance #Relative abundance transformation pseq_env_phyla_rarefy_1_relabund &lt;- microbiome::transform(pseq_env_phyla_rarefy_1, &quot;compositional&quot;) #Create, save, and display bar chart phylum_bar &lt;- microbiome::plot_composition(pseq_env_phyla_rarefy_1_relabund) ggsave(filename = &quot;./env_phyla_rarefy_1_relabund.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 100, width = 100) IRdisplay::display_png(file = &quot;./env_phyla_rarefy_1_relabund.png&quot;) Viewing the non-rarefied and rarefied based bar charts shows some differences. However, these are quite difficult to discern. 8.6.3 1R: Difference from non-rarefied To more easily see the differences we will subtract the two relative abundance tables from each other. This will produce a matrix of differences. #Value difference matrix single_rarefaction_diff &lt;- phyloseq::otu_table(pseq_env_phyla_relabund) - phyloseq::otu_table(pseq_env_phyla_rarefy_1_relabund) single_rarefaction_diff We can see there are differences. To make these differences even clearer let's make a histogram. #Histogram of differences hist(single_rarefaction_diff, main = &quot;Single rarefaction&quot;) What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 Although these values appear quite small keep in mind we are working with relative abundance values. Each sample has a total relative abundance of 1.00 so a relative abundance value of 0.01 is 1%. Let's see if we can get these differences smaller with multiple rounds of rarefaction. 8.7 Multiple Rarefaction (MR) iterations We will now carry out iterative rarefaction. 8.7.1 MR: Rarefaction The below loop creates a relative abundance table created by 10 rounds of iteration. Type the code and read the annotations to understand what is going on. Then run the code. #Iterative rarefaction to produce an average rarefied relative abundance table #Assign rarefaction size rarefaction_size &lt;- min(microbiome::readcount(pseq_env_phyla)) #Read in our rng seed vector load(&quot;rngseeds.RData&quot;) #Initalise where we will store the output #In this case we create the first iteration #Carry out first rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size #First random seed as the rng seed rngseed = rngseed_vec[1]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Relabund phyla table object relabund_phyla_table &lt;- as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) #Loop through the next 9 iterations #Add the relabund rarefied values to phyla_table for (i in 2:length(rngseed_vec)){ #Rarefy pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[i]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Sum values to phyla_table relabund_phyla_table &lt;- relabund_phyla_table + as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) } #Average the values of the summed relabund phyla_table relabund_phyla_table &lt;- relabund_phyla_table / length(rngseed_vec) 8.7.2 MR: Difference from non-rarefied We'll skip the bar chart this time and only look at the difference of the values. #Value difference matrix iterative_rarefaction_diff &lt;- as.matrix(phyloseq::otu_table(pseq_env_phyla_relabund) - relabund_phyla_table) iterative_rarefaction_diff #Histogram hist(iterative_rarefaction_diff) What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 You should notice that the differences are much smaller. This indicates that the structure of the iterative rarefied data is much closer to the non-rarefied data than the one rarefied data. This is what we want. 8.8 Iterating rarefaction task Superlative! Now that you know how to carry out iterative rarefaction I'll ask you to do it once more for the phyla data. Create a rarefaction averaged phyla relative abundance as we have done above but with 1000 rarefaction iterations. For this task use 153478 as the seed when creating your vector of 1000 rng seeds. Save this vector of rngseeds to a file called \"rngseeds_1000.RData\". Note: The iterative rarefaction step may take a few minutes. After creating the relative abundance matrix determine how different the values are compared to the non-rarefied relative abundance with a histogram. What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 Please attempt the task yourself before looking at the solution code in the below expandable box. Task solution code #Number of rarefaction iterations to be carried out rarefaction_iters &lt;- 1000 #Create rngseed vector #Set seed for reproducibility set.seed(153478) #Create the rngseed vector #Sample 1000 (number of iters) values from the number range 1-100,000 rngseed_vec &lt;- sample(x=1:100000, size = rarefaction_iters, replace = FALSE) #Save our rngseed vector save(rngseed_vec, file=&quot;rngseeds_1000.RData&quot;) #Reset seed set.seed(NULL) #Iterative rarefaction to produce an average rarefied relative abundance table #Assign rarefaction size rarefaction_size &lt;- min(microbiome::readcount(pseq_env_phyla)) #Read in our rng seed vector load(&quot;rngseeds_1000.RData&quot;) #Initalise where we will store the output #In this case we create the first iteration #Carry out first rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[1]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Relabund phyla table object relabund_phyla_table &lt;- as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) #Loop through the next 999 iterations #Add the relabund rarefied values to phyla_table for (i in 2:length(rngseed_vec)){ #Rarefy pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[i]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Sum values to phyla_table relabund_phyla_table &lt;- relabund_phyla_table + as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) } #Average the values of the summed relabund phyla_table relabund_phyla_table &lt;- relabund_phyla_table / length(rngseed_vec) #Value difference matrix iterative_rarefaction_1000_diff &lt;- as.matrix(phyloseq::otu_table(pseq_env_phyla_relabund) - relabund_phyla_table) iterative_rarefaction_diff #Histogram hist(iterative_rarefaction_diff) 8.9 Iterating rarefaction recap With this chapter you have learnt: How to create a vector of rngseeds How to use rng seeds to carry out iterative rarefaction In you real life analysis you would not use this method to create relative abundance taxonomy bar charts, you would use the non-rarefied relative abundance. However, this hopefully gave you a good idea of how iterative rarefaction works so we can utilise it the next 2 chapters for alpha and beta diversity analysis. Feel free to save then close and halt your \"Iterating_rarefaction.ipynb\" notebook. "],["09-Alpha_diversity.html", "Chapter 9 Alpha Diversity 9.1 \\(\\alpha\\): Setup 9.2 \\(\\alpha\\): Iterative rarefaction values 9.3 \\(\\alpha\\): Iterative rarefaction loop 9.4 \\(\\alpha\\): Metric and metadata data frame 9.5 \\(\\alpha\\): Long data frame 9.6 \\(\\alpha\\): Subset metrics 9.7 \\(\\alpha\\): Violin plot 9.8 \\(\\alpha\\): Stats 9.9 \\(\\alpha\\): Plot with stats 9.10 \\(\\alpha\\): Task 9.11 \\(\\alpha\\): Recap", " Chapter 9 Alpha Diversity In this chapter we'll carry out alpha diversity analysis using the iterative rarefaction approach. We will carry this out on the ASV counts rather than at a taxonomy level such as phyla. These materials are mostly a combination of the iterative rarefaction in this book and the alpha diversity analysis in the R community workshop. Due to this we won't go into great detail, instead focussing on giving you the code to be able to carry this out. 9.1 \\(\\alpha\\): Setup Create a new R jupyter notebook called \"Alpha_diversity.ipynb\". Load the required data and libraries. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;tidyverse&quot;) library(&quot;IRdisplay&quot;) library(&quot;ggpubr&quot;) #Load processed but unrarefied ASV data from main R community workshop load(&quot;phyloseq.RData&quot;) 9.2 \\(\\alpha\\): Iterative rarefaction values Before carrying out iterative rarefaction we need to decide on a few values Rarefaction size: The sequence depth to normalise samples to We are using the minimum sample depth here The size you choose will be based on your data and what you feel is appropriate More info in the R community workshop RNG seeds: The rng seeds we will use for all the rarefactions We created these in the previous chapter Rarefaction iterations: The number of rarefaction iterations we will use We are using 10 here based on the length of our rng seed vector We recommend you use 1000 in your real analysis #Rarefaction values #Rarefaction size #Minimum sample depth in this case rarefaction_size &lt;- min(microbiome::readcount(pseq)) #Load the vector of 10 rngseeds created in the previous chapter load(&quot;rngseeds.RData&quot;) #Number of rarefaction iterations to be carried out #Based on length of rng seed vector rarefaction_iters &lt;- length(rngseed_vec) 9.3 \\(\\alpha\\): Iterative rarefaction loop Now we will create averaged alpha diversity values through iterative rarefaction. We will carry this out by: Calculating initial alpha diversity values from the first iteration Looping through the subsequent rarefaction iterations and adding/summing calculated alpha diversity values to the initial alpha diversity values Dividing each value of the final summed alpha diversity by the number of rarefaction iterations. For this we will use the function microbiome::alpha() to calculate our alpha diversity values. #Loop to create iteration based rarefied alpha diversity values #Create data frame to contain final summed alpha diversity values #In this case we&#39;ll run the first rarefied alpha diversity analysis pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[1], verbose = FALSE) #Alpha diversity alpha_df_sum &lt;- microbiome::alpha(pseq_rarefy, index = &quot;all&quot;) #Loop through 2 to the number of iterations for (i in 2:rarefaction_iters){ pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[i], verbose = FALSE) #Alpha diversity alpha_df &lt;- microbiome::alpha(pseq_rarefy, index = &quot;all&quot;) #Add/sum the new data frame values to the sum data frame alpha_df_sum &lt;- alpha_df_sum + alpha_df } #Divide by number of rarefaction iterations to get average alpha_df_mean &lt;- alpha_df_sum / rarefaction_iters #Save alpha mean data frame save(alpha_df_mean, file = &quot;alpha_df_mean.RData&quot;) #Remove unneeded objects rm(pseq,alpha_df_sum, alpha_df) You can check the structure and contents of our alpha diversity data frame with head(). head(alpha_df_mean) There are a lot of diversity metrics. We are only interested in a few of them here but we will remove the other ones later on. 9.4 \\(\\alpha\\): Metric and metadata data frame Now that we have our alpha diversity values we will create a data frame that contains these values and metadata. In the below code we extract the metadata from the rarefied phyloseq object created in the last loop iteration above. This ensures we only acquire metadata from samples that are retained after rarefaction. The samples that are retained are always the same across our rarefaction iterations as samples are retained based on the rarefaction size/depth which is kept consistent across our rarefactions. #Combine metadata and alpha diversity mean values into one data frame #Extract metadata from rarefied phyloseq object metadf &lt;- phyloseq::sample_data(pseq) #Ensure row names are identical #if not sort alpha data frame rows by metadata row names if (identical(row.names(metadf), row.names(alpha_df_mean)) == FALSE) { alpha_df_mean &lt;- alpha_df_mean[row.names(metadf),] } #Combine with cbind (column bind) meta_alpha_mean_df &lt;- cbind(metadf,alpha_df_mean) head(meta_alpha_mean_df) #Remove rarefied phyloseq object that we do not need any more in this notebook rm(pseq_rarefy) From the output of head() you should see a table with the first set of columns being the metadata columns. The next set of columns is the alpha diversity metrics. 9.5 \\(\\alpha\\): Long data frame We will plot our alpha diversity values with ggplot2 functions. Before we carry this out we need to convert our wide data frame to a long data frame. We'll carry this out with tidyr::pivot_longer(). For this we want our metric values to become long. This means that instead of the alpha diversity values being spread across multiple rows and columns their will only be one value per row. Two columns will represent these values in the long format: metric: The name of the alpha diversity metric value: The value of the alpha diversity metric #Create long version for plotting #alpha_df_mean (no metadata) column names to be used for long conversion alpha_div_colnames &lt;- colnames(alpha_df_mean) #Wide to long meta_alpha_mean_long_df &lt;- tidyr::pivot_longer(data = meta_alpha_mean_df, #Change the alpha diversity names to long format #I.e. keep our metadata columns as separate columns #all_of() used to silence warning message cols = all_of(alpha_div_colnames) #Set column name to column called metric #Set values to column called value names_to = &quot;metric&quot;, values_to = &quot;value&quot; ) #Change our metric column to a factor #Useful for plotting meta_alpha_mean_long_df$metric &lt;- as.factor(meta_alpha_mean_long_df$metric) #Check head and dimensions of long data frame head(meta_alpha_mean_long_df) dim(meta_alpha_mean_long_df) #Remove unneeded objects rm(alpha_df_mean, metadf) 9.6 \\(\\alpha\\): Subset metrics There are a lot of diversity values created by microbiome::alpha(). For this tutorial we are only interested in: observed: The number of observed features (ASVs, Phlya, Species, etc.) chao1: The estimated real total number of features diversity_shannon: The Shannon diversity metric An estimate of feature diversity based on richness (presence/absence) and abundance The higher the value the higher the diversity We'll subset our long data frame to only retain rows with these metrics. We'll also use the utility of factors to order the metrics so they are plotted in our preferred order further down. #Process our long data frame #Subset our long alpha diversity data frame to only contain our metrics of choice metrics &lt;- c(&quot;observed&quot;, &quot;chao1&quot;,&quot;diversity_shannon&quot;) basic_alpha_metrics_long_df &lt;- meta_alpha_mean_long_df[ meta_alpha_mean_long_df$metric %in% metrics, ] #Change instances of diversity_shannon to shannon basic_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;diversity_shannon&quot;, replacement = &quot;shannon&quot;, x = basic_alpha_metrics_long_df$metric) #The gsub() function changes our factor to a character vector #Therefore change back to factor #We will also choose our order of the metric names for plotting basic_alpha_metrics_long_df$metric &lt;- factor(x = basic_alpha_metrics_long_df$metric, levels = c(&quot;observed&quot;,&quot;chao1&quot;,&quot;shannon&quot;)) #Check level order of metric factor column levels(basic_alpha_metrics_long_df$metric) #Check head of subsetted long data frame head(basic_alpha_metrics_long_df) With this data frame we can move onto visualisation. 9.7 \\(\\alpha\\): Violin plot To visualise the differences of the alpha diversity values between the four different media we'll use violin plots. We can use the function ggplot2::geom_violin() to carry this out. Additionally, we'll add a point for each value and colour it based on the site it canme from (UD, MD, or LD). The function ggforce::geom_sina() can be used for this. We'll use its parameter alpha() to make the points 50% (0.5) transparent. As we are plotting values from three different metrics we will split the plot into three separate plots. ggplot2::facet_wrap() can be used for this tasked with ~metric used to split the plot by the metrics. We also specify scales = \"free\" so each of the three plots has their own x and y scales. This is important when the values are drastically different such is the case between the observed and chao1 (&gt;100) compared to the shannon values (&lt;10). scales options The four scales are: \"fixed\" (default): All the scales are the same (fixed), based on the largest and smallest x and y values across all the plots. Useful where you want direct comparisons such as looking at teh overall pattern in ordination plots. \"free\": All the scales are free. Each plot's x and y values limits are based on the data within it. \"free_x\": The x axis is free and the y axis is fixed. \"free_y\": The y axis is free and the x axis is fixed. Which you wnat to use depends on your data and how you are facetting it. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot.png&quot;) 9.8 \\(\\alpha\\): Stats We can carry out statistics to compare the alpha diversity values between sample groups. 9.8.1 Kruskal Wallis test To determine if there is an overall difference in our data we'll use the Kruskal Wallis test. We'll carry this out using the media grouping for our three alpha diversity values. #Kruskal Wallis test #Observed ASVs kruskal.test(observed ~ media, data = meta_alpha_mean_df) #Chao1 estimator kruskal.test(chao1 ~ media, data = meta_alpha_mean_df) #Shannon diversity kruskal.test(shannon ~ media, data = meta_alpha_mean_df) All the p-values are less than 0.05 indicating statistical significance. That means we can move onto pairwise comparisons. 9.8.2 Paired wilcoxon test To determine what groups are significantly different from each other we can carry out paired Wilcoxon test. This tests #Paired wilcoxon test #Observed ASVs pairwise.wilcox.test(meta_alpha_mean_df$observed, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) #Chao1 estimator pairwise.wilcox.test(meta_alpha_mean_df$chao1, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) #Shannon diversity pairwise.wilcox.test(meta_alpha_mean_df$shannon, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) You'll see three p-value adjusted tables with all the values (except Shannon: ENV against TSA) being significant (&lt;0.05). 9.9 \\(\\alpha\\): Plot with stats Rather than having the plot and stats separate, we can add stats onto our plot. This can be carried out with the function stat_compare_means() from the `ggpubr package. 9.9.1 List of comparisons To produce pairwise comparisons with ggpubr::stat_compare_means() we need a list of the comparisons we want to carry out. We can create this with the function combn(), short for combination. We provide it with three parameters: Input data: This is a vector of the unique metadata categories to create the combinations from We are using our created uniq_media_values_chr_vec in this case We ensure that this is a vector of characters so the created combination list contains character vectors A list of character vectors is required for ggpubr::stat_compare_means() m =: The number of elements to choose when creating combinations. We choose 2 so we get all pair combinations simplify =: Indicates if the result should be simple (TRUE) or not (FALSE) TRUE returns a simplified array such as a matrix or a data frame FALSE returns a list. This is what we want as ggpubr::stat_compare_means() requires a list #To compare mean we need to create a list of comparisons #Create character vector of unique metadata values (media in this case) uniq_media_values_chr_vec &lt;- unique(as.character(basic_alpha_metrics_long_df$media)) uniq_media_values_chr_vec #Can use combn() to get comparisons my_comparisons &lt;- combn(uniq_media_values_chr_vec, m = 2, simplify = FALSE)) #Check contents and structure my_comparisons str(my_comparisons) 9.9.2 Violin plot with stats With our list of comparisons we can add ggpubr::stat_compare_means() to our ggplot2 code. This function will both calculate the Wilcoxon tests and add them to the plot. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;) 9.9.3 Reorder x-axis and stats ggplot orders the x-axis by alphabetical order. This is not normally wanted so we will convert our media column to a factor and order the levels how we want them. As the environmental samples can be seen as the baseline we will have them first. #Set order of media basic_alpha_metrics_long_df$media &lt;- factor(basic_alpha_metrics_long_df$media, #Set order of levels levels = c(&quot;ENV&quot;, &quot;CVP&quot;, &quot;KBC&quot;, &quot;TSA&quot;)) The stats in our previous plot were also not in a good order. We'll therefore reorder them. When doing this it is important to note that the first comparison in the lists is the bottom most stat in the plot. #Order comparisons my_ordered_comparisons &lt;- my_comparisons[c(1,2,6,4,3,5)] my_ordered_comparisons You'll notice this can be quite manual. It can be made easier when doing this yourself to roughly reorder, run the below code for your plot, then fix the stats reorder. With our media categories and comparisons reordered we can create the final plot. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_ordered_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;) 9.10 \\(\\alpha\\): Task As an optional task if you want more practice create a new violin plot that includes the following: Plots the metrics: \"chao1\" \"evenness_pielou\" renaming it as \"pielou\" \"diversity_fisher\" renaming it as \"fisher\" Ensure they are in the order \"chao1\", \"pielou\", then \"fisher\" The x-axis is separated by Site (UD, MD, LD) rather than media. Ensure the order is UD, MD, then LD Points are coloured by Media (ENV, CVP, KBC, and TSA) Ensure the order is ENV, CVP, KBC, then TSA Include Wilcoxon paired stats comparing the Sites Solution code Subset long alpha diversity table created earlier in this chapter to contain metrics of choice. #Process our long data frame #Subset our long alpha diversity data frame to only contain our metrics of choice metrics &lt;- c(&quot;chao1&quot;, &quot;evenness_pielou&quot;,&quot;diversity_fisher&quot;) subset_alpha_metrics_long_df &lt;- meta_alpha_mean_long_df[ meta_alpha_mean_long_df$metric %in% metrics, ] #Change instances of evenness_pielou to pielou subset_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;evenness_pieloue&quot;, replacement = &quot;pielou&quot;, x = subset_alpha_metrics_long_df$metric) #Change instances of diversity_fisher to fisher subset_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;diversity_fisher&quot;, replacement = &quot;fisher&quot;, x = subset_alpha_metrics_long_df$metric) #The gsub() function changes our factor to a character vector #Therefore change back to factor #We will also choose our order of the metric names for plotting subset_alpha_metrics_long_df$metric &lt;- factor(x = subset_alpha_metrics_long_df$metric, levels = c(&quot;chao1&quot;,&quot;pielou&quot;,&quot;fisher&quot;)) #Check level order of metric factor column levels(subset_alpha_metrics_long_df$metric) #Check head of subsetted long data frame head(subset_alpha_metrics_long_df) Create metadata combination list for plot stats #To compare mean we need to create a list of comparisons #Create character vector of unique metadata values (site in this case) uniq_site_values_chr_vec &lt;- unique(as.character(subset_alpha_metrics_long_df$site)) uniq_site_values_chr_vec #Can use combn() to get comparisons my_comparisons &lt;- combn(uniq_site_values_chr_vec, m = 2, simplify = FALSE)) #Check contents and structure my_comparisons str(my_comparisons) Reorder factors and comparisons #Reorder sites, media and comparisons #Set order of sites subset_alpha_metrics_long_df$site &lt;- factor(subset_alpha_metrics_long_df$site, #Set order of levels levels = c(&quot;UD&quot;, &quot;MD&quot;, &quot;LD&quot;)) #Set order of media subset_alpha_metrics_long_df$media &lt;- factor(subset_alpha_metrics_long_df$media, #Set order of levels levels = c(&quot;ENV&quot;, &quot;CVP&quot;, &quot;KBC&quot;, &quot;TSA&quot;)) #Order comparisons my_ordered_comparisons &lt;- my_comparisons[c(1,3,2)] my_ordered_comparisons Plot with stats #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(subset_alpha_metrics_long_df, aes(x = site, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Media&quot;, x = &quot;Site&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_ordered_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_site_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_site_violinplot_pairwise_wilcox.png&quot;) 9.11 \\(\\alpha\\): Recap In this chapter you have: Produced alpha diversity values through iterative rarefaction Created a long data frame containing metadata and specified alpha diversity metrics Visualised the group differences of alpha diversity metrics with violin plots Embedded paired Wilcoxon p-values in our violin plots With these skills and knowledge you will be able to carry out thorough investigations of alpha diversity in your future research. "],["10-Beta_diversity.html", "Chapter 10 Beta Diversity", " Chapter 10 Beta Diversity "]]
